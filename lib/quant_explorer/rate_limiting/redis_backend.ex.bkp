defmodule Quant.Explorer.RateLimiting.RedisBackend do
  @moduledoc """
  Redis-based rate limiter implementation for distributed systems.

  This backend supports:
  - Distributed rate limiting across multiple nodes
  - Lua scripts for atomic operations
  - All rate limiting algorithms (sliding window, token bucket, weighted)
  - Redis Streams for advanced tracking
  - High performance with pipelining

  Requires Redix dependency and Redis server.
  """

  @behaviour Quant.Explorer.RateLimiting.Behaviour

  alias Quant.Explorer.RateLimiting.Behaviour
  require Logger

  defstruct [:conn, :key_prefix, :scripts, :pipeline_size]

  @default_key_prefix "quant:rate_limit"
  @default_pipeline_size 10

  # Lua scripts for atomic operations
  @sliding_window_script """
  local key = KEYS[1]
  local window_ms = tonumber(ARGV[1])
  local limit = tonumber(ARGV[2])
  local now = tonumber(ARGV[3])
  local weight = tonumber(ARGV[4])

  -- Clean old entries
  local window_start = now - window_ms
  redis.call('ZREMRANGEBYSCORE', key, 0, window_start)

  -- Count current requests
  local current = redis.call('ZCOUNT', key, window_start, '+inf')

  if current < limit then
    -- Add new request
    redis.call('ZADD', key, now, now .. ':' .. weight)
    redis.call('EXPIRE', key, math.ceil(window_ms / 1000))
    return {1, limit - current - 1, window_ms}
  else
    -- Rate limited
    local oldest = redis.call('ZRANGE', key, 0, 0, 'WITHSCORES')
    local retry_after = 0
    if #oldest > 0 then
      retry_after = window_ms - (now - tonumber(oldest[2]))
    end
    return {0, 0, retry_after}
  end
  """

  @weighted_requests_script """
  local key = KEYS[1]
  local window_ms = tonumber(ARGV[1])
  local limit = tonumber(ARGV[2])
  local now = tonumber(ARGV[3])
  local weight = tonumber(ARGV[4])

  -- Clean old entries
  local window_start = now - window_ms
  redis.call('ZREMRANGEBYSCORE', key, 0, window_start)

  -- Calculate current weight
  local entries = redis.call('ZRANGE', key, 0, -1, 'WITHSCORES')
  local current_weight = 0
  for i = 1, #entries, 2 do
    local entry_data = string.match(entries[i], '.*:(%d+)')
    if entry_data then
      current_weight = current_weight + tonumber(entry_data)
    end
  end

  if current_weight + weight <= limit then
    -- Add new weighted request
    redis.call('ZADD', key, now, now .. ':' .. weight)
    redis.call('EXPIRE', key, math.ceil(window_ms / 1000))
    return {1, limit - current_weight - weight, window_ms}
  else
    -- Rate limited
    local oldest = redis.call('ZRANGE', key, 0, 0, 'WITHSCORES')
    local retry_after = 0
    if #oldest > 0 then
      retry_after = window_ms - (now - tonumber(oldest[2]))
    end
    return {0, limit - current_weight, retry_after}
  end
  """

  @token_bucket_script """
  local key = KEYS[1]
  local capacity = tonumber(ARGV[1])
  local refill_rate = tonumber(ARGV[2])
  local refill_period_ms = tonumber(ARGV[3])
  local now = tonumber(ARGV[4])
  local tokens_requested = tonumber(ARGV[5])

  -- Get current bucket state
  local bucket = redis.call('HMGET', key, 'tokens', 'last_refill')
  local tokens = tonumber(bucket[1]) or capacity
  local last_refill = tonumber(bucket[2]) or now

  -- Calculate tokens to add
  local time_passed = now - last_refill
  local tokens_to_add = math.floor(time_passed / refill_period_ms) * refill_rate
  tokens = math.min(tokens + tokens_to_add, capacity)

  if tokens >= tokens_requested then
    -- Consume tokens
    tokens = tokens - tokens_requested
    redis.call('HMSET', key, 'tokens', tokens, 'last_refill', now)
    redis.call('EXPIRE', key, math.ceil(refill_period_ms / 1000) * 2)
    return {1, tokens, 0}
  else
    -- Not enough tokens
    redis.call('HMSET', key, 'tokens', tokens, 'last_refill', now)
    redis.call('EXPIRE', key, math.ceil(refill_period_ms / 1000) * 2)
    local retry_after = math.ceil((tokens_requested - tokens) / refill_rate) * refill_period_ms
    return {0, tokens, retry_after}
  end
  """

  @impl true
  def init(opts \\ []) do
    redis_opts = Keyword.get(opts, :redis_opts, [])
    key_prefix = Keyword.get(opts, :key_prefix, @default_key_prefix)
    pipeline_size = Keyword.get(opts, :pipeline_size, @default_pipeline_size)

    case Redix.start_link(redis_opts) do
      {:ok, conn} ->
        # Load Lua scripts
        scripts = load_scripts(conn)

        state = %__MODULE__{
          conn: conn,
          key_prefix: key_prefix,
          scripts: scripts,
          pipeline_size: pipeline_size
        }

        {:ok, state}

      {:error, reason} ->
        {:error, reason}
    end
  end

  @impl true
  def check_and_consume(request_info, limit_config, state) do
    key = build_key(request_info, state.key_prefix)
    now = System.system_time(:millisecond)

    case execute_rate_limit_script(key, request_info, limit_config, now, state) do
      {1, remaining, retry_after_or_window} ->
        remaining_info = %{
          remaining: remaining,
          reset_time: calculate_reset_time(now, retry_after_or_window, limit_config),
          retry_after_ms: 0
        }
        {:ok, remaining_info, state}

      {0, remaining, retry_after_ms} ->
        remaining_info = %{
          remaining: remaining,
          reset_time: calculate_reset_time(now, retry_after_ms, limit_config),
          retry_after_ms: retry_after_ms
        }
        {{:error, :rate_limited}, remaining_info, state}
    end
  end

  @impl true
  def check_limit(request_info, limit_config, state) do
    # Use a dry-run approach - check without consuming
    key = build_key(request_info, state.key_prefix) <> ":check"
    now = System.system_time(:millisecond)

    case execute_rate_limit_script(key, request_info, limit_config, now, state) do
      {1, remaining, _} ->
        # Clean up the dry-run key
        Redix.command(state.conn, ["DEL", key])
        remaining_info = build_remaining_info(remaining, now, limit_config)
        {:ok, remaining_info, state}

      {0, remaining, retry_after_ms} ->
        # Clean up the dry-run key
        Redix.command(state.conn, ["DEL", key])
        remaining_info = %{
          remaining: remaining,
          reset_time: calculate_reset_time(now, retry_after_ms, limit_config),
          retry_after_ms: retry_after_ms
        }
        {{:error, :rate_limited}, remaining_info, state}
    end
  end

  @impl true
  def consume_limit(request_info, limit_config, state) do
    key = build_key(request_info, state.key_prefix)
    now = System.system_time(:millisecond)

    case execute_rate_limit_script(key, request_info, limit_config, now, state) do
      {_, remaining, retry_after_or_window} ->
        remaining_info = %{
          remaining: remaining,
          reset_time: calculate_reset_time(now, retry_after_or_window, limit_config),
          retry_after_ms: 0
        }
        {remaining_info, state}
    end
  end

  @impl true
  def get_limit_status(provider, endpoint, state) do
    key = "#{state.key_prefix}:#{provider}:#{endpoint}"
    now = System.system_time(:millisecond)

    # Get current status without modifying
    case Redix.command(state.conn, ["EXISTS", key]) do
      {:ok, 1} ->
        # Key exists, get details
        case Redix.command(state.conn, ["ZCOUNT", key, "-inf", "+inf"]) do
          {:ok, count} ->
            remaining_info = %{
              remaining: max(0, 60 - count),  # Assume default limit of 60
              reset_time: DateTime.add(DateTime.utc_now(), 60, :second),
              retry_after_ms: 0
            }
            {remaining_info, state}

          _ ->
            # Default response
            default_remaining_info(state)
        end

      {:ok, 0} ->
        # Key doesn't exist, no limits consumed
        default_remaining_info(state)
    end
  end

  @impl true
  def reset_limits(provider, endpoint_or_all, state) do
    pattern = case endpoint_or_all do
      :all -> "#{state.key_prefix}:#{provider}:*"
      endpoint -> "#{state.key_prefix}:#{provider}:#{endpoint}"
    end

    case Redix.command(state.conn, ["KEYS", pattern]) do
      {:ok, keys} ->
        if length(keys) > 0 do
          Redix.command(state.conn, ["DEL" | keys])
        end
        {:ok, state}

      {:error, reason} ->
        Logger.warning("Failed to reset limits: #{inspect(reason)}")
        {:ok, state}
    end
  end

  @impl true
  def cleanup(state) do
    # Redis automatically handles expiration, but we can do maintenance
    Logger.debug("Redis backend cleanup completed")
    {:ok, state}
  end

  @impl true
  def get_stats(provider_or_all, state) do
    # Get statistics from Redis
    pattern = case provider_or_all do
      :all -> "#{state.key_prefix}:stats:*"
      provider -> "#{state.key_prefix}:stats:#{provider}"
    end

    case Redix.command(state.conn, ["KEYS", pattern]) do
      {:ok, keys} ->
        stats = Enum.reduce(keys, %{}, fn key, acc ->
          case Redix.command(state.conn, ["HGETALL", key]) do
            {:ok, values} ->
              provider_name = key |> String.split(":") |> List.last() |> String.to_atom()
              stats_map = values |> Enum.chunk_every(2) |> Enum.into(%{}, fn [k, v] -> {k, v} end)
              Map.put(acc, provider_name, stats_map)

            _ ->
              acc
          end
        end)

        {stats, state}

      {:error, _reason} ->
        {%{}, state}
    end
  end

  @impl true
  def setup_distributed(nodes, state) do
    # Redis is inherently distributed, so this is mostly a no-op
    # Could be used to setup Redis Cluster connections
    Logger.info("Redis backend is ready for distributed operation across #{length(nodes)} nodes")
    {:ok, state}
  end

  @impl true
  def update_config(new_config, state) do
    # Update Redis connection or other configuration
    new_key_prefix = Keyword.get(new_config, :key_prefix, state.key_prefix)
    new_pipeline_size = Keyword.get(new_config, :pipeline_size, state.pipeline_size)

    new_state = %{state |
      key_prefix: new_key_prefix,
      pipeline_size: new_pipeline_size
    }

    {:ok, new_state}
  end

  # Private functions

  defp load_scripts(conn) do
    {:ok, sliding_window_sha} = Redix.command(conn, ["SCRIPT", "LOAD", @sliding_window_script])
    {:ok, weighted_requests_sha} = Redix.command(conn, ["SCRIPT", "LOAD", @weighted_requests_script])
    {:ok, token_bucket_sha} = Redix.command(conn, ["SCRIPT", "LOAD", @token_bucket_script])

    %{
      sliding_window: sliding_window_sha,
      weighted_requests: weighted_requests_sha,
      token_bucket: token_bucket_sha
    }
  end

  defp build_key(request_info, key_prefix) do
    "#{key_prefix}:#{request_info.provider}:#{request_info.endpoint}"
  end

  defp execute_rate_limit_script(key, request_info, limit_config, now, state) do
    script_sha = case limit_config.type do
      type when type in [:requests_per_minute, :requests_per_second, :requests_per_hour, :requests_per_day] ->
        state.scripts.sliding_window

      :weighted_requests ->
        state.scripts.weighted_requests

      :burst_allowance ->
        state.scripts.token_bucket
    end

    args = case limit_config.type do
      type when type in [:requests_per_minute, :requests_per_second, :requests_per_hour, :requests_per_day] ->
        [limit_config.window_ms, limit_config.limit, now, request_info.weight]

      :weighted_requests ->
        [limit_config.window_ms, limit_config.limit, now, request_info.weight]

      :burst_allowance ->
        refill_period_ms = div(limit_config.window_ms, limit_config.recovery_rate)
        [limit_config.burst_size, limit_config.recovery_rate, refill_period_ms, now, request_info.weight]
    end

    case Redix.command(state.conn, ["EVALSHA", script_sha, 1, key] ++ args) do
      {:ok, [allowed, remaining, retry_after]} ->
        {allowed, remaining, retry_after}

      {:error, reason} ->
        Logger.error("Redis script execution failed: #{inspect(reason)}")
        {0, 0, 60000}  # Default to rate limited with 1 minute retry
    end
  end

  defp calculate_reset_time(now, retry_after_or_window, limit_config) do
    case limit_config.type do
      :burst_allowance ->
        # For token bucket, retry_after is the time until enough tokens are available
        DateTime.add(DateTime.utc_now(), div(retry_after_or_window, 1000), :second)

      _ ->
        # For sliding window, use the window duration
        DateTime.add(DateTime.utc_now(), div(limit_config.window_ms, 1000), :second)
    end
  end

  defp build_remaining_info(remaining, now, limit_config) do
    %{
      remaining: remaining,
      reset_time: DateTime.add(DateTime.utc_now(), div(limit_config.window_ms, 1000), :second),
      retry_after_ms: 0
    }
  end

  defp default_remaining_info(state) do
    remaining_info = %{
      remaining: 60,  # Default assumption
      reset_time: DateTime.add(DateTime.utc_now(), 60, :second),
      retry_after_ms: 0
    }
    {remaining_info, state}
  end
end
